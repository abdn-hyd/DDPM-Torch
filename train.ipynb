{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80d2f66c",
   "metadata": {},
   "source": [
    "# 1. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08707913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Cifar10_Config:\n",
    "    # dataset config\n",
    "    cifar10_path = \"path/to/cifar-10-batches-py\"\n",
    "    train_batch_size = 128\n",
    "    eval_batch_size = 256\n",
    "    num_workers = 4\n",
    "    img_h = 32\n",
    "    img_w = 32\n",
    "\n",
    "    # training config\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    start_epoch = 0\n",
    "    num_epochs = 200\n",
    "    lr = 2e-4\n",
    "    output_dir = \"path/to/outputs/\"\n",
    "    save_image_epochs = 20\n",
    "    save_model_epochs = 20\n",
    "    save_generated_imgs_interval = 10\n",
    "    grid_rows = 16\n",
    "    grid_cols = 16\n",
    "    resume = None\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.999\n",
    "    warmup = 5000\n",
    "\n",
    "    # model config\n",
    "    in_channels = 3\n",
    "    hid_channels = 128\n",
    "    out_channels = 3\n",
    "    ch_multipliers = [1, 2, 2, 2]\n",
    "    num_res_blocks = 2\n",
    "    apply_attn = [False, True, False, False]\n",
    "    time_embedding_dim = 512\n",
    "    drop_rate = 0.1\n",
    "    resample_with_conv = True\n",
    "    beta_start = 1e-4\n",
    "    beta_end = 2e-2\n",
    "\n",
    "\n",
    "cifar10_train_config = Cifar10_Config()\n",
    "device = cifar10_train_config.device\n",
    "print(\"running on \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfc5b8d",
   "metadata": {},
   "source": [
    "# 2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd386b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torchinfo import summary\n",
    "from Dataloader import get_cifar10_dataloader\n",
    "from UNet import get_unet_model\n",
    "from Functions import create_images_grid\n",
    "from DDPM import DDPMScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99709e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the mode and dataloader\n",
    "model = get_unet_model(cifar10_train_config).to(device)\n",
    "dataloader = get_cifar10_dataloader(cifar10_train_config)\n",
    "\n",
    "# model summary\n",
    "input = torch.randn(cifar10_train_config.train_batch_size, cifar10_train_config.img_channels, cifar10_train_config.img_h, cifar10_train_config.img_w).to(device)\n",
    "t = torch.randint(0, cifar10_train_config.num_timesteps, (cifar10_train_config.train_batch_size,)).to(device)\n",
    "summary(\n",
    "    model,\n",
    "    input_data=(input, t),\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\"],\n",
    "    row_settings=[\"var_names\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aace5914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the optimizer, lr scheduler, criterion, DDPM scheduler\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=cifar10_train_config.lr, betas=(cifar10_train_config.beta1, cifar10_train_config.beta2))\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=cifar10_train_config.num_epochs * len(dataloader),\n",
    "    eta_min=1e-9,\n",
    "    last_epoch=-1,\n",
    ")\n",
    "# lr_scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "#         optimizer, lr_lambda=lambda t: min((t + 1) / cifar10_train_config.warmup, 1.0)\n",
    "#     ) if cifar10_train_config.warmup > 0 else None\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "ddpm_scheduler = DDPMScheduler(\n",
    "    num_timesteps=cifar10_train_config.num_timesteps,\n",
    "    beta_start=cifar10_train_config.beta_start,\n",
    "    beta_end=cifar10_train_config.beta_end,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886d499b-fae1-4094-a1f1-96389182b891",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cifar10_train_config.resume:\n",
    "    checkpoint = torch.load(cifar10_train_config.resume, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n",
    "    cifar10_train_config.start_epoch = checkpoint['epoch'] + 1\n",
    "\n",
    "print(\"start epoch: \", cifar10_train_config.start_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef514021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation(\n",
    "    cfg: dataclass,\n",
    "    epoch: int,\n",
    "    Scheduler: DDPMScheduler,\n",
    "    model: nn.Module,\n",
    "):\n",
    "    # Perform reverse diffusion process with noisy images.\n",
    "    xt = torch.randn(\n",
    "        cfg.eval_batch_size,\n",
    "        cfg.in_channels,\n",
    "        cfg.img_h,\n",
    "        cfg.img_w\n",
    "    ).to(cfg.device)\n",
    "\n",
    "    # Reverse diffusion for T timesteps\n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(range(Scheduler.num_timesteps - 1, -1, -1), desc=\"Generating images\", total=Scheduler.num_timesteps)\n",
    "        for t in progress_bar:\n",
    "            ts = t * torch.ones((xt.shape[0], ), dtype=torch.long)\n",
    "            noise_pred = model(xt, ts)\n",
    "            xt, x0 = Scheduler.sample_prev(xt, noise_pred, ts)\n",
    "\n",
    "            if t % cfg.save_generated_imgs_interval == 0:\n",
    "                generated_images = (xt + 1) / 2\n",
    "                generated_images = torch.clamp(generated_images, 0.0, 1.0)\n",
    "                generated_images = generated_images.detach().cpu()\n",
    "                generated_images = generated_images.permute(0, 2, 3, 1).numpy()\n",
    "                generated_images = (generated_images * 255).astype(\"uint8\")\n",
    "    \n",
    "                image_grid = create_images_grid(generated_images, rows=cfg.grid_rows, cols=cfg.grid_cols)\n",
    "                grid_save_dir = Path(cfg.output_dir, \"samples\", f\"epoch_{epoch}\")\n",
    "                grid_save_dir.mkdir(parents=True, exist_ok=True)\n",
    "                image_grid.save(Path(grid_save_dir, f\"generated_images_{t}.png\"))\n",
    "\n",
    "        progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed08d9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the training process\n",
    "def train_evaluate(\n",
    "    cfg: dataclass,\n",
    "    model: nn.Module,\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    criterion: nn.Module,\n",
    "    ddpm_scheduler: DDPMScheduler,\n",
    "    train: bool = True,\n",
    "    evaluate: bool = True,\n",
    "):\n",
    "    global_step = cfg.start_epoch * len(dataloader)\n",
    "    best_eval_loss = float(\"inf\")\n",
    "\n",
    "    for epoch in range(cfg.start_epoch, cfg.num_epochs):\n",
    "        progress_bar = tqdm(total=len(dataloader))\n",
    "        progress_bar.set_description(f\"Epoch {epoch}\")\n",
    "\n",
    "        if train:\n",
    "            model.train()\n",
    "\n",
    "            mean_loss = 0.0\n",
    "\n",
    "            for step, (imgs, _) in enumerate(dataloader):\n",
    "                imgs = imgs.to(device)\n",
    "                train_batch_size = imgs.shape[0]\n",
    "\n",
    "                # sample a random timestep for each image\n",
    "                t = torch.randint(\n",
    "                    0, ddpm_scheduler.num_timesteps, (train_batch_size,)\n",
    "                ).long()\n",
    "\n",
    "                # apply forward diffusion process at the given timestep\n",
    "                noisy_imgs, noise = ddpm_scheduler.forward_process(imgs, t)\n",
    "\n",
    "                # predict the noise\n",
    "                noise_pred = model(noisy_imgs, t)\n",
    "\n",
    "                # compute the loss\n",
    "                loss = criterion(noise_pred, noise)\n",
    "                mean_loss = mean_loss + (loss.detach().item() - mean_loss) / (step + 1)\n",
    "                best_eval_loss = min(best_eval_loss, mean_loss)\n",
    "\n",
    "                # backpropagation\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                lr_scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                progress_bar.update(1)\n",
    "                logs = {\"loss\": mean_loss, \"lr\": lr_scheduler.get_last_lr()[0], \"step\": global_step}\n",
    "                progress_bar.set_postfix(**logs)\n",
    "                global_step += 1\n",
    "\n",
    "            progress_bar.close()\n",
    "        \n",
    "        # evaluate\n",
    "        if evaluate:\n",
    "            if (epoch + 1) % cfg.save_image_epochs == 0 or epoch == cfg.num_epochs - 1:\n",
    "                model.eval()\n",
    "                generation(cfg, epoch, ddpm_scheduler, model)\n",
    "\n",
    "        if (epoch + 1) % cfg.save_model_epochs == 0 or epoch == cfg.num_epochs - 1:\n",
    "            checkpoint = {\n",
    "                'model': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'lr_scheduler': lr_scheduler.state_dict(),\n",
    "                'parameters': cfg,\n",
    "                'epoch': epoch\n",
    "            }\n",
    "            torch.save(checkpoint, Path(cfg.output_dir,\n",
    "                                        f\"unet{cfg.img_h}_{cfg.img_w}_e{epoch}.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0a4808-12fc-40f6-afd9-b611b015e858",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_evaluate(\n",
    "    cfg=cifar10_train_config,\n",
    "    model=model,\n",
    "    dataloader=dataloader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    ddpm_scheduler=ddpm_scheduler,\n",
    "    train=True,\n",
    "    evaluate=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
